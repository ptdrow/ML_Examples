{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Coding a K-Nearest Neighbors Classifier from scratch.</h1>\n",
    "\n",
    "This notebook is an introductory exercise of the K-Nearest Neighbors (KNN) method for classification.\n",
    "\n",
    "<h2>Introduction</h2>\n",
    "The K-Nearest Neighbors algorithm is a supervised learning algorithm for classifying data. The way it works is by treating the features of the items as dimensions in an Euclidean space so you can see each item as a point in the space. Its premise is that items from a same category should have similar values in their features, therefore be close to each other in the space.\n",
    "\n",
    "In order to classify an unknown item the KNN algorithm calculates its distance in the space to every other known item and choses the nearest  as reference to the prediction. How many will it chose? K. That's why it is called k-nearest neighbors. After knowing the categories from its k-nearest neighbors the algorithm will take a votation and select the most common category as the predicted category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Implementation</h1>\n",
    "Let's write a general implementation and then try it out with a dataset.\n",
    "<h2>Import libraries</h2>\n",
    "Start by importing some useful libraries:\n",
    "* ***Math*** for calculating the square root of a number\n",
    "* ***Pandas*** for dealing with the data\n",
    "* ***Counter*** for selecting the most common category\n",
    "* ***Matplotlib*** for ploting some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Calculate the distances</h2>\n",
    "In order to know which are the nearest points in the space you are going to need a way to calculate the distances in the space. There are different ways to define and calculate the required distance, I'm going to choose the Euclidean distance as it is more intuitive to me from a geometry point of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(xi,xj):\n",
    "    \"\"\"\n",
    "    Calculates the euclidean distance in a N-dimensional space between the points xi and xj\n",
    "    \n",
    "    Parameters:\n",
    "        xi, xj: numeric list or tuple representing each point.\n",
    "        \n",
    "    Returns:\n",
    "        distance (float): the euclidean distance between the points.\n",
    "    \"\"\"\n",
    "    \n",
    "    distance_squared = 0\n",
    "    for d in range(len(xi)):\n",
    "        distance_squared += (xj[d] - xi[d]) ** 2\n",
    "    return math.sqrt(distance_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = (2,1,1)\n",
    "x2 = (1,0,0)\n",
    "euclidean_dist(x1,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined a distance we can calculate that distance from a given point, which label is unknown, to all the other points which category labels we already know.\n",
    "So let's suppose we have the data in the form of a Pandas DataFrame and we know wich columns we want to take as dimensions for the Euclidean space in wich we are going to calculate distance. Then we will need to subset the dataframe by those columns and convert each row into the appropiate type in order to apply our distance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_all_distances(xi, data, columns):\n",
    "    \"\"\"\n",
    "    Calculates the Euclidean distance between a point and all the points in the data.\n",
    "    \n",
    "    Parameters:\n",
    "        xi      : Numeric list or tuple representing the point.\n",
    "        data    : Pandas dataframe with the training data.\n",
    "                  Each row will represent a point in the N-dimensional space.\n",
    "        columns : A list of the columns name to take as the dimensions of the Euclidean space. \n",
    "        \n",
    "    Returns:\n",
    "        distances (Series): the euclidean distances between the points.\n",
    "        \n",
    "    \"\"\"\n",
    "    #Convert data frame to points in n-dimensional space\n",
    "    points = data[columns].apply(tuple,axis=1)\n",
    "    #Calculate distance for each row\n",
    "    distances = points.apply(lambda x: euclidean_dist(xi,x))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function calculates all the distances to a point by:\n",
    "* Subseting the data by the desired columns and formating the rows into tuples (points).\n",
    "* Applying the *euclidean_dist* function to each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prediction</h2>\n",
    "For making a classification you have to calculate all the distances from a point of interest to the other known points, and then select the k-nearest to that point to let them vote. The category with the most votes is going to be the prediction.\n",
    "To achieve that we are going to sort the result of *calc_all_distances* and take the indices of the k-smallest distances. With the indices we can retrieve their labels in the target column and count them to choose the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn(xi, data, columns, target_column, k):\n",
    "    \"\"\"\n",
    "    Predicts the label for a given point by taking votes from its k-nearest neigbors\n",
    "    \n",
    "    Parameters:\n",
    "        xi           : Numeric list or tuple representing the point.\n",
    "        data         : Pandas dataframe with the training data.\n",
    "                       Each row will represent a point in the N-dimensional space.\n",
    "        columns      : A list of the columns names to take as the dimensions of the Euclidean space. \n",
    "        target_column: The name of the target feature\n",
    "        k            : The number of nearest neighbors to take into account\n",
    "        \n",
    "    Returns:\n",
    "        prediction (str): the predicted label for the point\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    all_distances = calc_all_distances(xi,data,columns)\n",
    "    k_nearest = list(all_distances.sort_values()[:k].index)\n",
    "    k_nearest_labels = data.loc[k_nearest, target_column]\n",
    "    poll = Counter(k_nearest_labels)\n",
    "    return poll.most_common()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now let's test it with data.\n",
    "<h1>Using the implementation</h1>\n",
    "I'm going to use the IRIS data set as its length and features makes it appropiate to use with KNN classification. You cand read more about the data in the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Iris)\n",
    "<h2>Load the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = pd.read_csv('/kaggle/input/iris/Iris.csv')\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using our *predict_knn* function we need to specify the columns that will form the dimensions of the Euclidean space and the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
      "Species\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(iris_data.columns[1:5])\n",
    "print(feature_columns)\n",
    "target_column = iris_data.columns[5]\n",
    "print(target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a ficticious flower point and see how it gets classified. I'm gonna arbitrarily choose k=3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "flower_point = (5.0, 4.0, 2.0, 1.5)\n",
    "k = 3\n",
    "print(predict_knn(flower_point,\n",
    "                  iris_data, \n",
    "                  feature_columns,\n",
    "                  target_column,\n",
    "                  k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now it seems to be working just fine. But what about the accuracy of our model?\n",
    "Because we don't have any other data to test let's check its perfomance with the train data. We are going to try to predict each point category in the dataset, by using the rest of the dataset each time, and compare the prediction with the actual category label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "predictions = list()\n",
    "for row in iris_data.itertuples():\n",
    "    dict_row = row._asdict()\n",
    "    xi = list()\n",
    "    for col in feature_columns:\n",
    "        xi.append(dict_row[col])\n",
    "    predictions.append(predict_knn(xi,\n",
    "                                   iris_data.drop(index=row.Index), \n",
    "                                   feature_columns, \n",
    "                                   target_column, \n",
    "                                   k))\n",
    "        \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above predicts the category for each row (you can expand the output to check the results). Now lets check how well it classified the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = iris_data.loc[:,target_column] == predictions\n",
    "accuracy = sum(correct_predictions)/len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we got a pretty good accuracy score. The reason why it does not have a perfect accuracy score is because for these featuras the point clouds of the categories Iris-versicolor and Iris-virginica are close to each other and somewhat overlapping in the Euclidean space. Therefore the points inside that overlapping zone are going to be hard to classify properly.\n",
    "\n",
    "You could try different k values in order to try to improve that result, but you have to be carefull to not overfit the model to this train data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
